{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c33675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading faker-37.11.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\abdel\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n",
      "Downloading faker-37.11.0-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.1/2.0 MB 907.3 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/2.0 MB 930.9 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 1.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/2.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-37.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ae97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Generation Complete ===\n",
      "Segment        rows=    60 | null_avg=0.000\n",
      "Portfolio      rows=   400 | null_avg=0.000\n",
      "Payment_Method rows=   600 | null_avg=0.000\n",
      "Project        rows=   180 | null_avg=0.000\n",
      "Employee       rows=   400 | null_avg=0.052\n",
      "Customer       rows=  8000 | null_avg=0.013\n",
      "Transactions   rows=  7000 | null_avg=0.016\n",
      "Unit           rows=  9000 | null_avg=0.189\n",
      "Owner          rows=  4500 | null_avg=0.001\n",
      "Owner_Ship     rows=  6257 | null_avg=0.000\n",
      "Investor       rows=   600 | null_avg=0.009\n",
      "Contractor     rows=   300 | null_avg=0.000\n",
      "All CSVs written to 'reocdb_faker'\n"
     ]
    }
   ],
   "source": [
    "# reocdb_faker_sql_compatible.py\n",
    "import os, random, csv\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "faker = Faker()\n",
    "random.seed(SEED); np.random.seed(SEED); Faker.seed(SEED)\n",
    "\n",
    "NUM_SEGMENTS        = 60\n",
    "NUM_EMPLOYEES       = 400\n",
    "NUM_CUSTOMERS       = 8000\n",
    "NUM_PROJECTS        = 180\n",
    "NUM_CONTRACTORS     = 300\n",
    "NUM_UNITS           = 9000\n",
    "NUM_TRANSACTIONS    = 7000\n",
    "NUM_PAYMENT_METHODS = 600\n",
    "NUM_OWNERS          = 4500\n",
    "NUM_INVESTORS       = 600\n",
    "NUM_PORTFOLIOS      = 400\n",
    "\n",
    "OUTPUT_PATH = \"reocdb_faker\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "segment_names     = [\"Premium\",\"Budget\",\"Investors\",\"Renters\",\"Corporate\",\"Retail\"]\n",
    "employee_roles    = [\"Sales\",\"Manager\",\"Agent\",\"Account\",\"Project Manager\",\"Support\"]\n",
    "customer_types    = [\"Buyer\",\"Renter\",\"Investor\",\"Prospect\"]\n",
    "unit_types        = [\"Apartment\",\"Villa\",\"Studio\",\"Commercial\"]\n",
    "unit_statuses     = [\"Available\",\"Sold\",\"Reserved\",\"Under Construction\"]\n",
    "tx_payment_status = [\"Paid\",\"Pending\",\"Cancelled\"]\n",
    "transaction_types = [\"Sale\",\"Rent\",\"Deposit\",\"Refund\"]\n",
    "portfolio_labels  = [\"Growth\",\"Income\",\"Balanced\",\"Speculative\",\"LongTerm\"]\n",
    "\n",
    "def unique_value(gen_func, used_set, max_tries=2000):\n",
    "    for _ in range(max_tries):\n",
    "        v = gen_func()\n",
    "        if v and v not in used_set:\n",
    "            used_set.add(v); return v\n",
    "    base = gen_func(); i = 1\n",
    "    while f\"{base}-{i}\" in used_set: i += 1\n",
    "    used_set.add(f\"{base}-{i}\"); return f\"{base}-{i}\"\n",
    "\n",
    "def choose_or_none(options, none_weight=0.0):\n",
    "    if none_weight <= 0: return random.choice(options)\n",
    "    pool = [None] * int(none_weight * 100) + list(options)\n",
    "    return random.choice(pool)\n",
    "\n",
    "def clean_text_cols(df):\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = (df[col].astype(str)\n",
    "                         .str.replace(r\"[\\r\\n]+\", \" \", regex=True)\n",
    "                         .str.strip())\n",
    "    return df\n",
    "\n",
    "used_emails, used_phones = set(), set()\n",
    "def gen_unique_email(company=False):\n",
    "    return unique_value(lambda: faker.company_email() if company else faker.email(), used_emails)\n",
    "def gen_unique_phone():\n",
    "    return unique_value(lambda: faker.phone_number(), used_phones)\n",
    "\n",
    "# =========================\n",
    "# 1) Segment\n",
    "# =========================\n",
    "df_Segment = pd.DataFrame([{\n",
    "    \"segment_id\": i,\n",
    "    \"segment_name\": segment_names[(i-1) % len(segment_names)],\n",
    "    \"description\": faker.sentence(nb_words=6),\n",
    "    \"target_income_range\": f\"{random.randint(10000,40000)}-{random.randint(50000,150000)}\"\n",
    "} for i in range(1, NUM_SEGMENTS+1)])\n",
    "\n",
    "# =========================\n",
    "# 2) Portfolio\n",
    "# =========================\n",
    "used_portfolio_names = set()\n",
    "portfolios = []\n",
    "for i in range(1, NUM_PORTFOLIOS+1):\n",
    "    pname = unique_value(lambda: random.choice(portfolio_labels) + \" \" + faker.lexify(text=\"??\").upper(),\n",
    "                         used_portfolio_names)\n",
    "    portfolios.append({\n",
    "        \"portfolio_id\": i,\n",
    "        \"portfolio_name\": pname,\n",
    "        \"description\": faker.sentence(nb_words=8),\n",
    "        \"Due_Date\": faker.date_between(start_date=\"-2y\", end_date=\"+2y\"),\n",
    "        \"escrow\": round(np.random.uniform(10_000, 500_000), 2),\n",
    "        \"estate_cost\": round(np.random.uniform(100_000, 5_000_000), 2),\n",
    "    })\n",
    "df_Portfolio = pd.DataFrame(portfolios)\n",
    "\n",
    "# =========================\n",
    "# 3) Payment_Method\n",
    "# =========================\n",
    "df_Payment_Method = pd.DataFrame([{\n",
    "    \"payment_method_number\": i,\n",
    "    \"type\": random.choice([\"Bank Transfer\",\"Credit Card\",\"Cash\",\"Cheque\",\"Online\"])\n",
    "} for i in range(1, NUM_PAYMENT_METHODS+1)])\n",
    "\n",
    "# =========================\n",
    "# 4) Project\n",
    "# =========================\n",
    "projects = []\n",
    "for i in range(1, NUM_PROJECTS+1):\n",
    "    start = faker.date_between(start_date=\"-5y\", end_date=\"-1y\")\n",
    "    end = start + timedelta(days=365 * random.randint(1, 4))\n",
    "    projects.append({\n",
    "        \"project_id\": i,\n",
    "        \"project_name\": f\"{faker.city()} Project {i}\",\n",
    "        \"start_date\": start,\n",
    "        \"end_date\": end,\n",
    "        \"location\": faker.city(),\n",
    "        \"unit_id\": None   # FK to Unit, will set after Unit generated\n",
    "    })\n",
    "df_Project = pd.DataFrame(projects)\n",
    "\n",
    "# =========================\n",
    "# 5) Employee\n",
    "# =========================\n",
    "df_Employee = pd.DataFrame([{\n",
    "    \"Employee_id\": i,\n",
    "    \"Employee_name\": faker.name(),\n",
    "    \"role\": random.choice(employee_roles)[:20],\n",
    "    \"phone\": gen_unique_phone(),\n",
    "    \"email\": gen_unique_email(company=True),\n",
    "    \"project_id\": choose_or_none(list(range(1, NUM_PROJECTS+1)), 0.8)\n",
    "} for i in range(1, NUM_EMPLOYEES+1)])\n",
    "\n",
    "# =========================\n",
    "# 6) Customer\n",
    "# =========================\n",
    "df_Customer = pd.DataFrame([{\n",
    "    \"customer_id\": i,\n",
    "    \"first_name\": faker.first_name(),\n",
    "    \"last_name\": faker.last_name(),\n",
    "    \"gender\": random.choice([\"Male\",\"Female\",\"Other\"]),\n",
    "    \"age\": random.randint(18, 85),\n",
    "    \"phone\": gen_unique_phone(),  # UNIQUE\n",
    "    \"email\": gen_unique_email(),\n",
    "    \"avg_income\": round(np.random.uniform(5_000, 200_000), 2),\n",
    "    \"customer_type\": random.choice(customer_types)[:30],\n",
    "    \"is_ReferenceOnly\": random.choice([\"T\",\"F\"]) if random.random()<0.05 else \"F\",\n",
    "    \"segment_id\": random.randint(1, NUM_SEGMENTS),\n",
    "    \"Employee_id\": choose_or_none(list(range(1, NUM_EMPLOYEES+1)), 0.75)\n",
    "} for i in range(1, NUM_CUSTOMERS+1)])\n",
    "\n",
    "# =========================\n",
    "# 7) Transactions\n",
    "# =========================\n",
    "transactions = []\n",
    "for i in range(1, NUM_TRANSACTIONS+1):\n",
    "    amount = round(np.random.uniform(2_000, 5_000_000), 2)\n",
    "    transactions.append({\n",
    "        \"transaction_id\": i,\n",
    "        \"name\": f\"TXN-{i}-{faker.lexify(text='???').upper()}\",\n",
    "        \"transaction_date\": faker.date_between(start_date=\"-4y\", end_date=\"today\"),\n",
    "        \"amount\": amount,\n",
    "        \"tax\": round(amount * random.choice([0.0, 0.05, 0.1, 0.14]), 2),\n",
    "        \"discount_amount\": round(amount * random.choice([0.0, 0.01, 0.03, 0.05]), 2),\n",
    "        \"payment_status\": random.choice(tx_payment_status),\n",
    "        \"transaction_type\": random.choice(transaction_types),\n",
    "        \"customer_id\": random.randint(1, NUM_CUSTOMERS),\n",
    "        \"payment_method_number\": random.randint(1, NUM_PAYMENT_METHODS),\n",
    "        \"employee_id\": choose_or_none(list(range(1, NUM_EMPLOYEES+1)), 0.8)\n",
    "    })\n",
    "df_Transactions = pd.DataFrame(transactions)\n",
    "txn_by_id = df_Transactions.set_index(\"transaction_id\")\n",
    "\n",
    "# =========================\n",
    "# 8) Unit\n",
    "# =========================\n",
    "units = []\n",
    "for i in range(1, NUM_UNITS+1):\n",
    "    txn_fk = None; cust_fk = None\n",
    "    if random.random() < 0.35:\n",
    "        # Only link to Sale/Rent\n",
    "        while True:\n",
    "            cand = random.randint(1, NUM_TRANSACTIONS)\n",
    "            if txn_by_id.loc[cand, \"transaction_type\"] in {\"Sale\",\"Rent\"}:\n",
    "                txn_fk = cand\n",
    "                cust_fk = int(txn_by_id.loc[cand, \"customer_id\"])\n",
    "                break\n",
    "    units.append({\n",
    "        \"unit_id\": i,\n",
    "        \"type\": random.choice(unit_types),\n",
    "        \"area\": round(np.random.uniform(35.0, 450.0), 2),\n",
    "        \"status\": random.choice(unit_statuses),\n",
    "        \"price\": round(np.random.uniform(50_000, 2_500_000), 2),\n",
    "        \"location\": faker.city(),\n",
    "        \"floor_number\": random.randint(0, 30),\n",
    "        \"transaction_id\": txn_fk,\n",
    "        \"customer_id\": cust_fk,\n",
    "        \"portfolio_id\": choose_or_none(list(range(1, NUM_PORTFOLIOS+1)), 0.67),\n",
    "        \"monthly_rent\": round(np.random.uniform(4_000, 80_000), 2) if random.random()<0.35 else None\n",
    "    })\n",
    "df_Unit = pd.DataFrame(units)\n",
    "\n",
    "# Link Project.unit_id randomly to existing Units (schema has no Unit.project_id)\n",
    "any_unit_ids = df_Unit[\"unit_id\"].tolist()\n",
    "df_Project[\"unit_id\"] = [random.choice(any_unit_ids) if any_unit_ids else None for _ in df_Project.index]\n",
    "\n",
    "# =========================\n",
    "# 9) Owner\n",
    "# =========================\n",
    "df_Owner = pd.DataFrame([{\n",
    "    \"owner_id\": i,\n",
    "    \"first_name\": faker.first_name(),\n",
    "    \"last_name\": faker.last_name(),\n",
    "    \"address\": faker.address().replace(\"\\n\", \", \"),\n",
    "    \"phone\": gen_unique_phone(),\n",
    "    \"email\": gen_unique_email(),\n",
    "    \"type\": random.choice([\"Individual\",\"Company\"]),\n",
    "    \"registration_date\": faker.date_between(start_date=\"-6y\", end_date=\"today\"),\n",
    "    \"unit_id\": choose_or_none(any_unit_ids, 0.85)  # mostly NULL\n",
    "} for i in range(1, NUM_OWNERS+1)])\n",
    "\n",
    "# =========================\n",
    "# 10) Owner_Ship\n",
    "# =========================\n",
    "owner_ship = []\n",
    "pair = set()\n",
    "for owner_id in df_Owner[\"owner_id\"]:\n",
    "    k = random.choice([0,1,1,2,3])\n",
    "    if k:\n",
    "        for u in random.sample(any_unit_ids, k=k):\n",
    "            if (owner_id, u) not in pair:\n",
    "                owner_ship.append({\"Owner_id\": owner_id, \"Unit_id\": u})\n",
    "                pair.add((owner_id, u))\n",
    "df_Owner_Ship = pd.DataFrame(owner_ship)\n",
    "\n",
    "# =========================\n",
    "# 11) Investor\n",
    "# =========================\n",
    "df_Investor = pd.DataFrame([{\n",
    "    \"investor_id\": i,\n",
    "    \"investor_name\": faker.name() if random.random()<0.6 else faker.company(),\n",
    "    \"phone\": gen_unique_phone(),\n",
    "    \"email\": gen_unique_email(),\n",
    "    \"company_name\": faker.company() if random.random()<0.5 else None,\n",
    "    \"portfolio_id\": choose_or_none(list(range(1, NUM_PORTFOLIOS+1)), 0.2)\n",
    "} for i in range(1, NUM_INVESTORS+1)])\n",
    "\n",
    "# =========================\n",
    "# 12) Contractor\n",
    "# =========================\n",
    "contractors = []\n",
    "for i in range(1, NUM_CONTRACTORS+1):\n",
    "    s = faker.date_between(start_date=\"-5y\", end_date=\"-2y\")\n",
    "    e = s + pd.Timedelta(days=30 * random.randint(30, 200))\n",
    "    contractors.append({\n",
    "        \"contractor_id\": i,\n",
    "        \"contractor_name\": faker.company(),\n",
    "        \"phone\": gen_unique_phone(),\n",
    "        \"email\": gen_unique_email(company=True),\n",
    "        \"project_cost\": round(np.random.uniform(100_000, 8_000_000), 2),\n",
    "        \"start_date\": s,\n",
    "        \"end_date\": e,\n",
    "        \"project_count\": random.randint(1, 40),\n",
    "        \"payment_terms\": random.choice([\"30 days\",\"60 days\",\"Advance\",\"Milestone\"]),\n",
    "        \"project_id\": random.randint(1, NUM_PROJECTS)\n",
    "    })\n",
    "df_Contractor = pd.DataFrame(contractors)\n",
    "\n",
    "# =========================\n",
    "# VALIDATIONS (mirror DDL)\n",
    "# =========================\n",
    "def assert_unique(df, cols, name):\n",
    "    if df.duplicated(subset=cols).any():\n",
    "        dups = df[df.duplicated(subset=cols, keep=False)].sort_values(cols)\n",
    "        raise ValueError(f\"[DUPLICATES] {name}: duplicate values in {cols}\\n{dups.head(10)}\")\n",
    "\n",
    "def assert_fk(child_df, child_col, parent_df, parent_col, name):\n",
    "    if child_df is None or len(child_df)==0: return\n",
    "    child_vals = set(pd.to_numeric(child_df[child_col].dropna(), errors=\"coerce\").dropna().astype(int))\n",
    "    parent_vals = set(pd.to_numeric(parent_df[parent_col], errors=\"coerce\").dropna().astype(int))\n",
    "    missing = child_vals - parent_vals\n",
    "    if missing:\n",
    "        raise ValueError(f\"[FK VIOLATION] {name}: {child_col}->{parent_col} missing: {list(missing)[:10]} ...\")\n",
    "\n",
    "# PKs\n",
    "assert_unique(df_Segment, [\"segment_id\"], \"Segment\")\n",
    "assert_unique(df_Portfolio, [\"portfolio_id\"], \"Portfolio\")\n",
    "assert_unique(df_Payment_Method, [\"payment_method_number\"], \"Payment_Method\")\n",
    "assert_unique(df_Project, [\"project_id\"], \"Project\")\n",
    "assert_unique(df_Employee, [\"Employee_id\"], \"Employee\")\n",
    "assert_unique(df_Customer, [\"customer_id\"], \"Customer\")\n",
    "assert_unique(df_Transactions, [\"transaction_id\"], \"Transactions\")\n",
    "assert_unique(df_Unit, [\"unit_id\"], \"Unit\")\n",
    "assert_unique(df_Owner, [\"owner_id\"], \"Owner\")\n",
    "assert_unique(df_Owner_Ship, [\"Owner_id\",\"Unit_id\"], \"Owner_Ship\")\n",
    "assert_unique(df_Investor, [\"investor_id\"], \"Investor\")\n",
    "assert_unique(df_Contractor, [\"contractor_id\"], \"Contractor\")\n",
    "\n",
    "# Business constraints\n",
    "assert_unique(df_Customer, [\"phone\"], \"Customer.phone UNIQUE\")\n",
    "if not set(df_Transactions[\"payment_status\"]).issubset(set(tx_payment_status)):\n",
    "    raise ValueError(\"[CHECK] Transactions.payment_status has values outside ('Paid','Pending','Cancelled')\")\n",
    "\n",
    "# FKs\n",
    "assert_fk(df_Employee.dropna(subset=[\"project_id\"]), \"project_id\", df_Project, \"project_id\", \"Employee.project_id\")\n",
    "assert_fk(df_Customer.dropna(subset=[\"segment_id\"]), \"segment_id\", df_Segment, \"segment_id\", \"Customer.segment_id\")\n",
    "assert_fk(df_Customer.dropna(subset=[\"Employee_id\"]), \"Employee_id\", df_Employee, \"Employee_id\", \"Customer.Employee_id\")\n",
    "assert_fk(df_Transactions.dropna(subset=[\"customer_id\"]), \"customer_id\", df_Customer, \"customer_id\", \"Transactions.customer_id\")\n",
    "assert_fk(df_Transactions.dropna(subset=[\"payment_method_number\"]), \"payment_method_number\", df_Payment_Method, \"payment_method_number\", \"Transactions.payment_method_number\")\n",
    "assert_fk(df_Transactions.dropna(subset=[\"employee_id\"]), \"employee_id\", df_Employee, \"Employee_id\", \"Transactions.employee_id\")\n",
    "assert_fk(df_Unit.dropna(subset=[\"transaction_id\"]), \"transaction_id\", df_Transactions, \"transaction_id\", \"Unit.transaction_id\")\n",
    "assert_fk(df_Unit.dropna(subset=[\"customer_id\"]), \"customer_id\", df_Customer, \"customer_id\", \"Unit.customer_id\")\n",
    "assert_fk(df_Unit.dropna(subset=[\"portfolio_id\"]), \"portfolio_id\", df_Portfolio, \"portfolio_id\", \"Unit.portfolio_id\")\n",
    "assert_fk(df_Owner.dropna(subset=[\"unit_id\"]), \"unit_id\", df_Unit, \"unit_id\", \"Owner.unit_id\")\n",
    "assert_fk(df_Owner_Ship, \"Owner_id\", df_Owner, \"owner_id\", \"Owner_Ship.Owner_id\")\n",
    "assert_fk(df_Owner_Ship, \"Unit_id\", df_Unit, \"unit_id\", \"Owner_Ship.Unit_id\")\n",
    "assert_fk(df_Investor.dropna(subset=[\"portfolio_id\"]), \"portfolio_id\", df_Portfolio, \"portfolio_id\", \"Investor.portfolio_id\")\n",
    "assert_fk(df_Contractor.dropna(subset=[\"project_id\"]), \"project_id\", df_Project, \"project_id\", \"Contractor.project_id\")\n",
    "\n",
    "# Consistency: Units with txn must be Sale/Rent, and if Unit.customer_id set then == Transaction.customer_id\n",
    "if not df_Unit[\"transaction_id\"].isna().all():\n",
    "    merged = df_Unit.merge(\n",
    "        df_Transactions[[\"transaction_id\",\"transaction_type\",\"customer_id\"]],\n",
    "        on=\"transaction_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_unit\",\"_txn\"),\n",
    "    )\n",
    "    linked = merged[merged[\"transaction_id\"].notna()].copy()\n",
    "\n",
    "    # 1) Only Sale/Rent for linked units\n",
    "    bad_type = linked[~linked[\"transaction_type\"].isin([\"Sale\",\"Rent\"])]\n",
    "    if not bad_type.empty:\n",
    "        raise ValueError(\"[LOGIC] Unit linked to non-Sale/Rent:\\n\"\n",
    "                         f\"{bad_type[['unit_id','transaction_id','transaction_type']].head(10)}\")\n",
    "\n",
    "    # 2) Customer alignment (robust to suffix naming)\n",
    "    unit_cust_col = \"customer_id_unit\" if \"customer_id_unit\" in linked.columns else \\\n",
    "                    (\"customer_id_x\" if \"customer_id_x\" in linked.columns else \"customer_id\")\n",
    "    txn_cust_col  = \"customer_id_txn\"  if \"customer_id_txn\"  in linked.columns else \\\n",
    "                    (\"customer_id_y\" if \"customer_id_y\" in linked.columns else \"customer_id\")\n",
    "\n",
    "    both = linked[unit_cust_col].notna() & linked[txn_cust_col].notna()\n",
    "    bad_cust = linked[both & (linked[unit_cust_col].astype(int) != linked[txn_cust_col].astype(int))]\n",
    "    if not bad_cust.empty:\n",
    "        raise ValueError(\"[LOGIC] Unit.customer_id != Transaction.customer_id:\\n\"\n",
    "                         f\"{bad_cust[['unit_id','transaction_id', unit_cust_col, txn_cust_col]].head(10)}\")\n",
    "\n",
    "# =========================\n",
    "# CLEAN & EXPORT (safe CSVs)\n",
    "# =========================\n",
    "tables = {\n",
    "    \"Segment\":        df_Segment,\n",
    "    \"Portfolio\":      df_Portfolio,\n",
    "    \"Payment_Method\": df_Payment_Method,\n",
    "    \"Project\":        df_Project,\n",
    "    \"Employee\":       df_Employee,\n",
    "    \"Customer\":       df_Customer,\n",
    "    \"Transactions\":   df_Transactions,\n",
    "    \"Unit\":           df_Unit,\n",
    "    \"Owner\":          df_Owner,\n",
    "    \"Owner_Ship\":     df_Owner_Ship,\n",
    "    \"Investor\":       df_Investor,\n",
    "    \"Contractor\":     df_Contractor,\n",
    "}\n",
    "tables = {k: clean_text_cols(v) for k,v in tables.items()}\n",
    "\n",
    "for name, df in tables.items():\n",
    "    df.to_csv(\n",
    "        os.path.join(OUTPUT_PATH, f\"{name}.csv\"),\n",
    "        index=False,\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        escapechar=\"\\\\\",\n",
    "        encoding=\"utf-8-sig\"\n",
    "    )\n",
    "\n",
    "print(\"=== Data Generation Complete ===\")\n",
    "for n, d in tables.items():\n",
    "    print(f\"{n:14} rows={len(d):6} | null_avg={d.isna().mean().mean():.3f}\")\n",
    "print(f\"All CSVs written to '{OUTPUT_PATH}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
